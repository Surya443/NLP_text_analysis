{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "02b29cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rvbha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5d8c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "workbook = openpyxl.load_workbook('Input.xlsx')\n",
    "worksheet = workbook.active\n",
    "url_list = []\n",
    "for row in worksheet.iter_rows(values_only=True):\n",
    "    url_list.append(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "059a057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = url_list[1::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "617eb1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://insights.blackcoffer.com/ai-in-healthcare-to-improve-patient-outcomes/\n"
     ]
    }
   ],
   "source": [
    "print(url_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aaf48b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['StopWords_Auditor.txt', 'StopWords_Currencies.txt', 'StopWords_DatesAndNumbers.txt','StopWords_Generic.txt',\n",
    "             'StopWords_GenericLong.txt','StopWords_Geographic.txt','StopWords_Names.txt']\n",
    "\n",
    "# Define the output filename\n",
    "output_filename = 'stopwords.txt'\n",
    "\n",
    "# Open the output file in write mode\n",
    "with open(output_filename, 'w') as output_file:\n",
    "    # Loop through the input files\n",
    "    for filename in filenames:\n",
    "        # Open each input file in read mode\n",
    "        with open(filename, 'r') as input_file:\n",
    "            # Read the contents of the file and write them to the output file\n",
    "            output_file.write(input_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30b1acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stopwords.txt','r') as f:\n",
    "    stop_words = [i.strip() for i in f]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5f33ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url_list[2])\n",
    "content = response.content\n",
    "    \n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(content, 'html.parser')\n",
    "text = soup.get_text()\n",
    "    \n",
    "# Tokenize the text and remove stop words\n",
    "words = nltk.word_tokenize(text)\n",
    "sentence = nltk.sent_tokenize(text)\n",
    "words = [word.lower() for word in words if word.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "35ad23d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1874"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d600c190",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [i.strip() for i in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "99befc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = open('positive-words.txt','r')\n",
    "neg = open('negative-words.txt','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da18a27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_words = [i.strip() for i in neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ef4e8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = [i.strip() for i in pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c52f416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(words):\n",
    "    \n",
    "    pos_score,neg_score = 0,0\n",
    "\n",
    "    for i in words:\n",
    "        if i in positive_words:\n",
    "            pos_score+=1\n",
    "        if i in negative_words:\n",
    "             neg_score+=1\n",
    "        if i not in positive_words or i not in negative_words:\n",
    "            pass\n",
    "    polarity_score = (pos_score - neg_score)/(pos_score + neg_score + 0.000001)\n",
    "    subjectivity_score = (pos_score + neg_score)/(len(words) + 0.000001)\n",
    "    return pos_score, neg_score, polarity_score, subjectivity_score\n",
    "\n",
    "pos_score,neg_score,polarity_score,subjectivity_score = sentiment_analysis(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "019e5179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 42 0.3823529383650519 0.07257203838176518\n"
     ]
    }
   ],
   "source": [
    "print(pos_score,neg_score,polarity_score,subjectivity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8e0300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1618e307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average sentence length: 29.82\n",
      "Percentage of complex words: 30.45%\n",
      "fog index :24.108844542990887\n",
      "complex words : 899\n",
      "avg_words_per_sentence : 29.82\n"
     ]
    }
   ],
   "source": [
    "def analysis_of_readability(sentences):\n",
    "    complex_word_count = 0\n",
    "    word_count = 0\n",
    "    sentence_length = 0\n",
    "    for sentence in sentences:\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        word_count += len(words)\n",
    "        sentence_length += 1\n",
    "        for word in words:\n",
    "            vowel_count = sum(1 for letter in word if letter in 'aeiouAEIOU')\n",
    "            if vowel_count > 2:\n",
    "                complex_word_count += 1\n",
    "    \n",
    "    avg_sentence_length = word_count / sentence_length\n",
    "    avg_words_per_sentence = word_count / len(sentences)\n",
    "    percent_complex_words = (complex_word_count / word_count) * 100\n",
    "    fog_index = 0.4*(avg_sentence_length + percent_complex_words)\n",
    "    \n",
    "    return avg_sentence_length, percent_complex_words, fog_index, complex_word_count, avg_words_per_sentence\n",
    "\n",
    "# Call the function with the scraped sentences\n",
    "avg_sentence_length, percent_complex_words, fog_index, complex_words, avg_words_per_sentence = analysis_of_readability(sentence)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Average sentence length: {avg_sentence_length:.2f}\")\n",
    "print(f\"Percentage of complex words: {percent_complex_words:.2f}%\")\n",
    "print(f\"fog index :{fog_index}\")\n",
    "print(f\"complex words : {complex_words}\")\n",
    "print(f\"avg_words_per_sentence : {avg_words_per_sentence:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bd9d2499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(words):\n",
    "    stop_words_nltk = set(stopwords.words('english'))\n",
    "    punc = ['!','?',',',':','-']\n",
    "    word_nltk = [word.lower() for word in words if word.lower() not in stop_words_nltk and punc]\n",
    "    return len(word_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "95c4716b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1835"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b1059849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complexwords(words):\n",
    "    vowel_count = 0\n",
    "    for word in words:\n",
    "        if i in words in ['a','e','i','o','u','A','E','I','O','U']:\n",
    "            vowel_count += 1 \n",
    "    complex_count = vowel_count/len(words)\n",
    "    return complex_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "44c8937b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(complexwords(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726186bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPUEnv",
   "language": "python",
   "name": "gpuenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
